<!DOCTYPE html>
<html lang="en">

    <head>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <meta name=viewport content="width=device-width, initial-scale=1">

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-CBC1D21RJT"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-CBC1D21RJT');
        </script>

        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="author" content:"Yonatan Bisk">
        <link rel="canonical" href="https://yonatanbisk.com">
        <title>11-777 MultiModal Machine Learning</title>
        <meta name="title" content="11-777 MMML">
        <meta name="description" content="Multimodal Machine Learning 11-777 - at CMU">

        <!-- Open Graph -->
        <meta property="og:type" content="website">
        <meta property="og:url" content="https://YonatanBisk.com/teaching">
        <meta property="og:title" content:"Yonatan Bisk">
        <meta property="og:image" content="https://yonatanbisk.com/images/cmu-logo.png">
        <meta property="og:description" content="Multimodal Machine Learning 11-777 - at CMU">

        <!-- Twitter -->
        <meta property="twitter:card" content="summary_large_image">
        <meta property="twitter:url" content="https://YonatanBisk.com/teaching">
        <meta property="twitter:title" content:"Yonatan Bisk">
        <meta property="twitter:image" content="https://yonatanbisk.com/images/cmu-logo.png">
        <meta property="twitter:description" content="Multimodal Machine Learning 11-777- at CMU">

        <link rel="stylesheet" href="https://yonatanbisk.com/main.css">
        <link rel="icon" type="image/png" href="https://yonatanbisk.com/images/cmu-icon.png">
    </head>
    <body>

        <div class="jumbotron" style="padding-top:10px">
          <div class="container">
              <center><h1>11-777: <b>M</b>ulti<b>M</b>odal <b>M</b>achine <b>L</b>earning</h1></center>
          </div>
        </div>

      <main role="main">
        <center><h3>Spring 2022&nbsp;&nbsp;&nbsp;&nbsp;<a href="../class_projects.html">Previous Projects</a></h3></center>
        <div>This course focuses on core techniques and modern advances for integrating different "modalities" into a shared representation or reasoning system.  Specifically, these include text, audio, images/videos and action taking.</div><br>

          <div class="table">
            <div class="row">
              <div class="col-sm-12">
              <ul>
                <li><b>Time & Place</b>: 10:10am - 11:30am on Tu/Th (Doherty Hall 2210)</li>
                <li><b>Canvas</b>: <a href="https://canvas.cmu.edu/courses/27101">Lectures and additional details (coming soon)</a></li>
                <li><b>Course questions and discussion</b>: <a href="https://mmml-s22.slack.com">Slack</a> <br>Registered students will be invited daily the first week of class</li>
                <li><b>GitHub Template</b>: <a href="https://github.com/ybisk/11-777-template">https://github.com/ybisk/11-777-template</a></li>
              </ul>
              </div>
            </div>
          <hr>
            <div class="card-columns">
              <div class="card student sm-3" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=https://yonatanbisk.com/images/YonatanBisk_square.jpg class="card-img" alt="Yonatan Bisk" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>Instructor</b></h5>
                      <p class="card-text">Yonatan Bisk</p>
                      <p class="card-text"><small class="text-muted"><a href="mailto:ybisk@cs.cmu.edu">ybisk@cs.cmu</a></small>
                      </p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
              <div class="card student sm-3" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=images/liwei.jpg class="card-img" alt="Li-Wei Chen" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>TA</b></h5>
                      <p class="card-text">Li-Wei Chen</p>
                      <p class="card-text"><small class="text-muted"><a href="liweiche@cs">liweiche@cs.cmu.edu</a></small></p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
              <div class="card student sm-2" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=images/tachung.jpg class="card-img" alt="Ta-Chung Chi" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>TA</b></h5>
                      <p class="card-text">Ta-Chung Chi</p>
                      <p class="card-text"><small class="text-muted"><a href="tachungc@andrew.cmu.edu">tachungc@andrew</a></small></p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
            </div> <!-- close columns -->
            <div class="card-columns">
              <div class="card student sm-2" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=images/alex.jpg class="card-img" alt="Hyukjae (Alex) Kwark" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>TA</b></h5>
                      <p class="card-text">Hyukjae (Alex) Kwark</p>
                      <p class="card-text"><small class="text-muted"><a href="hkwark@andrew.cmu.edu">hkwark@andrew</a></small></p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
              <div class="card student sm-2" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=images/Dong.jpg class="card-img" alt="Dong Won" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>TA</b></h5>
                      <p class="card-text">Dong Won Lee</p>
                      <p class="card-text"><small class="text-muted"><a href="dongwonl@cs.cmu.edu">dongwonl@cs</a></small></p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
              <div class="card student sm-2" style="max-width: 300px;">
                <div class="row no-gutters">
                  <div class="col-md-6">
                      <img src=images/yuchen.jpg class="card-img" alt="Yuchen Xu" style="width:250px;">
                  </div>
                  <div class="col-md-6">
                    <div class="card-body">
                      <h5 class="card-title"><b>TA</b></h5>
                      <p class="card-text">Yuchen Xu</p>
                      <p class="card-text"><small class="text-muted"><a href="yuchenxu@andrew.cmu.edu">yuchenxu@andrew</a></small></p>
                    </div> <!-- card-body -->
                  </div> <!-- col -->
                </div> <!-- row -->
              </div> <!-- card -->
            </div> <!-- column -->
          <hr>
          <h4><b>Slack and Canvas</b></h4>
          <p>All course communication will happen via slack and canvas.  All videos will be posted to Canvas for offline viewing though aspects of the class/teaching will be interactive in the zoom sessions.</p>
          <p><b>Slack</b>
          <ul>
            <li><b>#general</b>: For questions about lectures, the course, or help from others on class projects</li>
            <li><b>#team-N-X</b>: Each team should come up with a name and create their own private channel (invite TAs and instructor).  Use the same name for your GitHub fork and pin the link to the channel.  Please also invite us to the GitHub. Example: #team-fun-vizwiz</li>
            <li><b>#dataset-XYZ</b>: Each core dataset will also have its own slack channel that anyone can join (across teams) to ask for help on setup, preprocessing, and other issues that might arise.</li>
            <li><b>Private Messages</b>: If there is a question you would like to address to the instructors, please send a DM on slack.  Please check #general-questions first and post there when possible.</li>
          </ul>
          <hr>
          <h4><b>Assignments Timeline and Grading</b></h4>

          The course is primarily project based, but there will be readings throughout the course which are only graded via participation.

          <br>
          <br>
          <b>Project Timeline and Assignments:</b> (see links for more details)
                <table class="table table-hover table-condensed">
                <tr class="d-flex" style="border-top:none;">
                  <td class="col-sm-2" style="border-top:none;">Feb 03</td>
                  <td class="col-sm-1" style="border-top:none;"></td>
                  <td class="col-sm-6" style="border-top:none;">Groups Formed</td>
                  <td class="col-sm-1" style="border-top:none;"></td>
                </tr>

                <tr class="d-flex" style="border-top:none;">
                  <td class="col-sm-2" style="border-top:none;">Feb 10</td>
                  <td class="col-sm-1" style="border-top:none;">R1</td>
                  <td class="col-sm-6" style="border-top:none;"><a href="https://github.com/ybisk/11-777-template/blob/main/Reports/1-Dataset-Proposal-and-Analysis/report.pdf">Dataset Proposal and Analysis (as a group)</a></td>
                  <td class="col-sm-1" style="border-top:none;">(10%)</td>
                </tr>
                
                <tr class="d-flex">
                  <td class="col-sm-2" style="border-top:none;">Mar 03</td>
                  <td class="col-sm-1" style="border-top:none;">R2</td>
                  <td class="col-sm-6" style="border-top:none;"><a href="https://github.com/ybisk/11-777-template/blob/main/Reports/2-Related-Work-and-Model-Proposal/report.pdf">Related Work and Model Proposal</a></td>
                  <td class="col-sm-1" style="border-top:none;">(15%)</td>
                </tr>
                
                <tr class="d-flex">
                  <td class="col-sm-2" style="border-top:none;">Mar 31</td>
                  <td class="col-sm-1" style="border-top:none;">R3</td>
                  <td class="col-sm-6" style="border-top:none;"><a href="https://github.com/ybisk/11-777-template/blob/main/Reports/3-Baselines-and-Analysis/report.pdf">Baseline Analysis</a></td>
                  <td class="col-sm-1" style="border-top:none;">(15%)</td>
                </tr>
                
                <tr class="d-flex">
                  <td class="col-sm-2" style="border-top:none;">Finals Week</td>
                  <td class="col-sm-1" style="border-top:none;"></td>
                  <td class="col-sm-6" style="border-top:none;"><a href="https://docs.google.com/presentation/d/161ObB-71Nh77Cv1kYlonHAmlRT5OuRQCI1yHIzow_7c/edit?usp=sharing">Presentation</a></td>
                  <td class="col-sm-1" style="border-top:none;">(10%)</td>
                </tr>

                <tr class="d-flex">
                  <td class="col-sm-2" style="border-top:none;">May 6</td>
                  <td class="col-sm-1" style="border-top:none;">Final</td>
                  <td class="col-sm-6" style="border-top:none;"><a href="https://github.com/ybisk/11-777-template/blob/main/Reports/4-Final-Report/report.pdf">Completed Report</a></td>
                  <td class="col-sm-1" style="border-top:none;">(20%)</td>
                </tr>
                </table>
          <br>
          <b>Participation:</b><br>
          Participation in Class or Slack (20%)<br>Participation is evaluated as "actively asking/answering questions based on the lectures, readings, and/or assisting other teams with project issues". Concretely, this means that every novel question or helpful answer provided in Slack will count for 1%, up to a total of 20% of your grade. Two bonus points can be earned (22%).
          <br><br>
          <b>Paper Summaries:</b><br>
          Paper Summaries (10%)<br>Writing a three sentence summary describing the paper you read earns you 1pt. This summary will be submitted in three text boxes.  Specifically, A. The goal of the paper, B. Explain the key insight, C. State a key limitation or important extension. There will be 11 opportunities, so you one bonus point can be earned (11%).  Paper summaries are due the following Tuesday night (1 week after being assigned).

          <br>
          <br>
          <b>Submission Policies:</b><br>
          <ul>
            <li>All deadlines are midnight EST (determined by Canvas submission)</li>
            <li><i>Everyone </i> must submit a PDF of the report to Canvas so we can give individual grades</li>
            <li>Late days: Every team has a budget of 6 late days. They will be automatically calculated, after which 2% absolute is removed from max grade.</li>
          </ul>

          <hr>
          <h4><b>Tasks & Datasets</b></h4>
          The course will be primarily centered on a few datasets/tasks to facilitate cross-team collaboration and technical assistance. If your team has a good reason to work on something else, please reach out so we can discuss it and put together a proposal.<br><br>

          <br>
          <h5><b>Simulator Based</b></h5>
          <table class="table table-condensed table-striped">
            <tr class="d-flex">
              <td class="col-md-3"><a href="https://arxiv.org/abs/2010.07954">Room-Across-Room</a></td>
              <td class="col-md-2"><a href="https://github.com/google-research-datasets/RxR">Code</a></td>
              <td class="col-md-7">Multilingual Embodied Navigation </td>
            </tr>

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://arxiv.org/abs/1912.01734">ALFRED</a></td>
              <td class="col-md-2"><a href="https://github.com/askforalfred/alfred">Code</a></td>
              <td class="col-md-7">Embodied instruction following with interaction</td>
            </tr>

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://arxiv.org/abs/2110.00534">TEACh</a></td>
              <td class="col-md-2"><a href="https://github.com/alexa/teach">Code</a></td>
              <td class="col-md-7">Embodied Teaching (and Dialogue)</td>
            </tr>

          </table>

          <br>
          <h5><b>Question Answering & Captioning</b></h5>
          <table class="table table-condensed table-striped">
            <tr class="d-flex">
              <td class="col-md-3"><a href="https://textvqa.org/">TextVQA</a></td>
              <td class="col-md-2"><a href="https://textvqa.org/">Code</a></td>
              <td class="col-md-7">Text in images (referring expressions and reading)</td>
            </tr>

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://webqna.github.io/">WebQA</a></td>
              <td class="col-md-2"><a href="https://github.com/WebQnA/WebQA_Baseline">Code</a></td>
              <td class="col-md-7">Multihop Visual QA</td>
            </tr>

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://vizwiz.org/">VizWiz</a></td>
              <td class="col-md-2"><a href="https://vizwiz.org/tasks-and-datasets/vqa/">VQA</a> and 
                                   <a href="https://vizwiz.org/tasks-and-datasets/image-captioning/">Captioning</a></td>
              <td class="col-md-7">Visual models for blind users</td>
            </tr>

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.html">Social-IQ</a></td>
              <td class="col-md-2"><a href="https://github.com/A2Zadeh/Social-IQ">Code</a><br><a href="https://www.thesocialiq.com/">Proj page</a></td>
              <td class="col-md-7">Video Question Answering focused on social interactions</td>
            </tr>
        </table>

          <br>
          <h5><b>Multi-turn QA</b></h5>
          <table class="table table-condensed table-striped">
            <tr class="d-flex">
              <td class="col-md-3"><a href="https://compguesswhat.github.io/">CompGuessWhat?!</a></td>
              <td class="col-md-2"></td>
              <td class="col-md-7">Visual Guessing Game and Attribute Prediction</td>
            </tr>


            <tr class="d-flex">
              <td class="col-md-3"><a href="https://arxiv.org/abs/1906.01530">PhotoBook Dialogue</a></td>
              <td class="col-md-2"><a href="https://dmg-photobook.github.io/datasets.html">Data</a></td>
              <td class="col-md-7">Visual reference game via dialogue</td>
            </tr>

          </table>

          <br>
          <h5><b>Audio</b></h5>
          <table class="table table-condensed table-striped">

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://groups.csail.mit.edu/sls/downloads/placesaudio/">Spoken Image Captions</a></td>
              <td class="col-md-2"></td>
              <td class="col-md-7">A series of audio corpora and corresponding images for connecting audio directly to image regions.</td>
            </tr>
          </table>

          <br>
          <h5><b>Video</b></h5>
          <table class="table table-condensed table-striped">

            <tr class="d-flex">
              <td class="col-md-3"><a href="https://tvqa.cs.unc.edu/">TVQA</a></td>
              <td class="col-md-2"></td>
              <td class="col-md-7">Video Question Answering Dataset</td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-3"><a href="https://eric-xw.github.io/vatex-website/index.html">VATEX</a></td>
              <td class="col-md-2"></td>
              <td class="col-md-7">Multilingual Video Captioning and Translation</td>
            </tr>
          </table>



          <br>
          <h5><b>Physical hardware / robots / sensors ... </b></h5>
          <table class="table table-condensed table-striped">

            <tr class="d-flex">
              <td class="col-md-12">What about physical hardware? robots? tasks not datasets? Let's talk.</td>
            </tr>

          </table>
          <br><br>
          <b>Compute</b>
          Limited AWS and Google Cloud compute credits will be made available to each group, so please consider both your interests and available compute resources when deciding on a dataset/project.
          <br>
          <hr>
          <h4><b>Lectures</b></h4>
          <table class="table table-striped">
            <thead>
              <tr class="d-flex">
                <th class="col-md-6">Tuesday</th>
                <th class="col-md-6">Thursday</th>
              </tr>
            </thead>
            <tr class="d-flex">
              <td class="col-md-6">
                Jan 18: <b>Course Structure</b>
                    <ul><li>Research and technical challenges</li><li>Syllabus and requirements</li></ul>
              </td>
              <td class="col-md-6">
                Jan 20: <b>Multimodal applications and datasets</b><br>
                      <ul><li>Research tasks and datasets</li> <li>Team projects</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                    <ul>
                      <li><a href="https://arxiv.org/abs/1705.09406">Multimodal Machine Learning: A Survey and Taxonomy</a> Sections 1-4</li>
                      <li><a href="https://arxiv.org/abs/1206.5538">Representation Learning: A Review and New Perspectives</a> Sections 1-3, 6-8, 11 </li>
              </td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Jan 25: <b>Basics: "Deep learning"</b> <br>
                      <ul><li>Language, Vision, Audio</li> <li>Loss functions and neural networks</li></ul>
              </td>
              <td class="col-md-6">
                Jan 27: <b>Basics: Optimization</b><br>
                      <ul><li>Gradients and backprop</li> <li>Practical deep learning optimization</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: A listed or proposed dataset/task
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Feb 1: <b>Unimodal representations (Vision)</b><br>
                      <ul><li>CNNs</li> <li>Residuals and Skip connections</li></ul>
              </td>
              <td class="col-md-6">
                Feb 3: <b>Unimodal representations (Language)</b><br>
                      <ul><li>Gating and LSTMs</li> <li>Transformers</li><li><font color="red">Groups formed, sign up for project hours</font></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                <ul>
                  <li><a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a></li>
                  <li><a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></li>
                  <li><a href="https://arxiv.org/abs/1506.02078">Visualizing and Understanding Recurrent Networks</a></li>
                  <li><a href="https://arxiv.org/abs/1805.04623">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a></li>
                </ul>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Feb 8 <b><font color="blue">Project Hours (Project ideas)</font></b>
              </td>
              <td class="col-md-6">
                Feb 10: <b><font color="blue">Project Hours (Project ideas)</font></b><ul><li><font color="red">R1: Dataset Proposal and Analysis</font></li>
              </td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-12" colspan=2>
                Readings: A paper of your choosing which is relevant to your project. <br><b>Note: </b>Team members must choose different papers. </td>
              </td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Feb 15: <b>Multimodal & Coordinated Representations </b><br>
                      <ul><li>Auto-encoders</li> <li>CCA</li><li>Multi-view Clustering</li></ul>
              </td>
              <td class="col-md-6">
                Feb 17: <b>Alignment and Attention</b><br>
                      <ul><li>Explicit - Dynamic Time Warping</li> <li>Implicit -- Attention</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                <ul>
                  <li><a href="https://link.springer.com/chapter/10.1007/978-3-642-15561-1_2">Every Picture Tells a Story: Generating Sentences from Images</a></li>
                  <li><a href="https://www.aclweb.org/anthology/N12-1094/">Detecting Visual Text</a></li>
                  <li><a href="https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00166">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions</a></li>
                  <li><a href="https://arxiv.org/abs/1511.02799">Neural Module Networks</a></li>
                </ul>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Feb 22: <b>Alignment + Representation</b><br>
                      <ul><li>Self-attention</li> <li>Multimodal Transformers</li></ul>
              </td>
              <td class="col-md-6">
                Feb 24: <b>Alignment + Representation (Cont)</b><br>  
                      <ul><li>Self-attention models</li> <li>Multimodal Transformers</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                <ul>
                  <li><a href="https://arxiv.org/abs/1906.00295">Multimodal Transformer for Unaligned Multimodal Language Sequences</a></li>
                  <li><a href="https://arxiv.org/abs/2004.06165">Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks</a></li>
                  <li><a href="https://arxiv.org/abs/2011.15124">Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTsâ€¨</a></li>
                  <li><a href="https://arxiv.org/abs/2102.03334">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</a></li>
                </ul>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Mar 1: <b>Alignment + Representation (Cont)</b><br>
                      <ul><li>Video Transformers</li><li>Self-Attention for Vision</li></ul>
              </td>
              <td class="col-md-6">
                Mar 3: <b>Ethics (Guest: <a href="https://strubell.github.io/">Emma Strubell</a>)</b>
                <ul><li><font color="red">R2: Related Work and Model Proposal</font></li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: None</td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Mar 8: <b>Spring Break!</b><br>
              </td>
              <td class="col-md-6">
                Mar 10: <b>Spring Break!</b>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: None </td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Mar 15: <b><font color="blue">Project Hours (Research Discussion)</font></b>
              </td>
              <td class="col-md-6">
                Mar 17: <b><font color="blue">Project Hours (Research Discussion)</font></b>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: A paper of your choosing which is relevant to your project. <br><b>Note: </b>Team members must choose different papers. </td>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Mar 22: <b>Alignment + Translation</b><br>
                      <ul><li>Module Networks</li><li>Tree-based & Stack models</li></ul>
              </td>
              <td class="col-md-6">
                Mar 24: <b>Fusion and co-learning</b><br>
                      <ul><li>Multi-kernel learning and fusion</li><li>Few shot learning and co-learning</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                <ul>
                  <li><a href="https://arxiv.org/abs/2007.15543">PixL2R: Guiding Reinforcement Learning Using Natural Language by Mapping Pixels to Rewards</a></li>
                  <li><a href="https://dl.acm.org/doi/10.1145/3136755.3136801">Multimodal sentiment analysis with word-level fusion and reinforcement learning</a></li>
                  <li><a href="https://language-play.github.io/">Language Conditioned Imitation Learning Over Unstructured Data</a></li>
                </ul>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Mar 29: <b>Reinforcement Learning</b><br>
                      <ul><li>Markov Decision Processes</li><li>Q-learning and policy gradients</li></ul>
              </td>
              <td class="col-md-6">
                Mar 31: <b>Multimodal RL</b>
                <ul><li>Deep Q learning</li><li>Multimodal applications</li><font color="red">R3: Baseline analysis</font></li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings:
                <ul>
                  <li><a href="https://arxiv.org/abs/1910.09664">Learning to Map Natural Language Instructions to Physical Quadcopter Control using Simulated Flight</a></li>
                  <li><a href="https://arxiv.org/abs/2110.07342">FILM: Following Instructions in Language with Modular Methods</a></li>
                  <li><a href="https://cliport.github.io/">CLIPort: What and Where Pathways for Robotic Manipulation</a></li>
                </ul>
            </tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Apr 5: <b>Embodiment</b>
                        <ul><li>Action as a modality</li></ul>
              </td>
              <td class="col-md-6">
                Apr 7: <b>-- NO CLASS --</b>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: None
            </td></tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Apr 12: <b>Embodiment (cont)</b>
                        <ul><li>Language to Control</li></ul>
              </td>
              <td class="col-md-6">
                Apr 14: <b>New research directions</b>
                      <ul><li>Recent publications</li></ul>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: 
                <ul>  
                  <li><a href="https://say-can.github.io/">Do As I Can, Not As I Say: Grounding Language in Robotic Affordances </a></li>
                  <li><a href="https://jerryxu.net/GroupViT/">GroupViT: Semantic Segmentation Emerges from Text Supervision</a></li>
                  <li><a href="https://arxiv.org/abs/2204.03162">Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality</a></li>
                  <li><a href="https://arxiv.org/abs/2203.15867">Image Retrieval from Contextual Descriptions</a></li>
                  <li><a href="https://arxiv.org/abs/2202.04053">DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers</a></li>
                </ul>
            </td></tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Apr 19: <b><font color="blue">Project Hours (Final)</font></b><br><br>
              </td>
              <td class="col-md-6">
                Apr 21: <b><font color="blue">Project Hours (Final)</font></b>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: None
            </td></tr>
            <tr class="d-flex">
              <td class="col-md-6">
                Apr 26: <b><a href="https://dpfried.github.io/">Daniel Fried</a></b>
              </td>
              <td class="col-md-6">
                Apr 28: <b><a href="https://cpaxton.github.io/about/">Chris Paxton</a></b>
              </td>
            </tr>
            <tr class="d-flex"><td class="col-md-12" colspan=2>
                Readings: 
                <ul>  
                  <li><a href="https://arxiv.org/abs/1711.04987">Unified Pragmatic Models for Generating and Following Instructions</a></li>
                  <li><a href="https://arxiv.org/abs/1806.02724">Speaker-Follower Models for Vision-and-Language Navigation</a></li>
                  <li><a href="https://arxiv.org/abs/2110.10189">StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects</a></li>
                </ul>
            </td></tr>
            </td></tr>
            <tr class="d-flex">
              <td class="col-md-6">
                May 5 (5:30-8:30pm): <font color="red">Project Presentations (Hybrid: PH 100)</font>
              </td>
              <td class="col-md-6">
                May 6: <b><font color="red">Final Reports Due</font></b> 
              </td>
            </tr> <!-- row -->
          </table> <!-- table -->

      </main>
  </body>
</html>

